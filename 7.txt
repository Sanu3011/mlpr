# ML Practical 7: Improving Performance of Classifier Models
# Name: Gayatri Ganesh Kakde
# Roll No: 3338  

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv("SMSSpamCollection", sep='\t', names=['label','text'])
print("Dataset shape:", df.shape)

# Preprocessing
df.shape

!pip install nltk

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

nltk.download('stopwords')
nltk.download('punkt')

# Initialize stopwords + stemmer
swords = stopwords.words('english')
ps = PorterStemmer()

# Tokenization example
tokens = word_tokenize('How are you friends?')
clean_tokens = [word for word in tokens if word not in swords]
stemmed_tokens = [ps.stem(word) for word in clean_tokens]
print("After stopwords removal:", clean_tokens)
print("After stemming:", stemmed_tokens)

# Text cleaning function
def clean_text(sent):
    tokens = word_tokenize(sent)
    clean = [word for word in tokens if word.isalpha()]
    clean = [ps.stem(word) for word in clean if word not in swords]
    return clean

# TF-IDF Feature Extraction
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(analyzer=clean_text)
x = df['text']
y = df['label']
x_new = tfidf.fit_transform(x)

# Visualize HAM vs SPAM
plt.figure(figsize=(6,4))
sns.countplot(x=y)
plt.title("Count of HAM vs SPAM Messages")
plt.xlabel("Label")
plt.ylabel("Count")
plt.show()

# Train-Test Split
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size=0.25, random_state=1)

# MODEL 1: Naive Bayes
from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(x_train.toarray(), y_train)
y_pred_nb = nb.predict(x_test.toarray())

# Confusion Matrix for Naive Bayes
from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, classification_report
plt.figure(figsize=(5,4))
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_nb)
plt.title("Confusion Matrix: Naive Bayes")
plt.show()
print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))
print(classification_report(y_test, y_pred_nb))

# MODEL 2: Logistic Regression (Required Probabilistic Model)
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(max_iter=2000)
lr.fit(x_train, y_train)
y_pred_lr = lr.predict(x_test)

# Confusion Matrix for Logistic Regression
plt.figure(figsize=(5,4))
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lr)
plt.title("Confusion Matrix: Logistic Regression")
plt.show()
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print(classification_report(y_test, y_pred_lr))

# Cross Validation
from sklearn.model_selection import cross_val_score

# Naive Bayes CV
nb_cv_scores = cross_val_score(nb, x_new.toarray(), y, cv=5, scoring='accuracy')
print("Naive Bayes 5-Fold CV Accuracy:", nb_cv_scores)
print("Naive Bayes CV Mean Accuracy:", nb_cv_scores.mean())

# Logistic Regression CV
lr_cv_scores = cross_val_score(lr, x_new, y, cv=5, scoring='accuracy')
print("Logistic Regression 5-Fold CV Accuracy:", lr_cv_scores)
print("Logistic Regression CV Mean Accuracy:", lr_cv_scores.mean())

# Hyperparameter Tuning: Logistic Regression
from sklearn.model_selection import GridSearchCV
param_grid = {
    'C': [0.1, 1, 10],
    'penalty': ['l2'],
    'solver': ['liblinear', 'lbfgs']
}

lr_grid = GridSearchCV(LogisticRegression(max_iter=2000),
                       param_grid,
                       cv=3,
                       scoring='accuracy',
                       n_jobs=-1)

lr_grid.fit(x_train, y_train)
print("Best Hyperparameters (Logistic Regression):", lr_grid.best_params_)
best_lr = lr_grid.best_estimator_

# Evaluate Tuned Logistic Regression
y_pred_lr_tuned = best_lr.predict(x_test)

plt.figure(figsize=(5,4))
ConfusionMatrixDisplay.from_predictions(y_test, y_pred_lr_tuned)
plt.title("Confusion Matrix: Tuned Logistic Regression")
plt.show()

print("Tuned Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr_tuned))
print(classification_report(y_test, y_pred_lr_tuned))

# Final Summary
print("\n=== Model Comparison ===")
print("Naive Bayes Accuracy:", accuracy_score(y_test, y_pred_nb))
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr))
print("Tuned Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_lr_tuned))
print("\nNaive Bayes CV Mean Accuracy:", nb_cv_scores.mean())
print("Logistic Regression CV Mean Accuracy:", lr_cv_scores.mean())
